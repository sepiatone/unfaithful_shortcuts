{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_deepseek_thinking_model(model_id: str) -> bool:\n",
    "    return \"reason\" in model_id or (\"r1\" in model_id and \"deepseek\" in model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_thinking_model(model_id: str) -> bool:\n",
    "    is_google_thinking_model = \"gemini\" in model_id and \"thinking\" in model_id\n",
    "    is_qwen_thinking_model = \"qwen\" in model_id and \"qwq\" in model_id\n",
    "    return is_deepseek_thinking_model(model_id) \\\n",
    "        or is_anthropic_thinking_model(model_id) \\\n",
    "        or is_google_thinking_model \\\n",
    "        or is_qwen_thinking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_anthropic_thinking_model(model_id: str) -> bool:\n",
    "    return \"claude-3.7-sonnet\" in model_id and \"_\" in model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_thinking_model(model_id):\n",
    "    extra_body = {\n",
    "        \"include_reasoning\": True,\n",
    "        \"reasoning\": {},\n",
    "        # \"provider\": {\n",
    "        #     \"allow_fallbacks\": False,\n",
    "        #     \"order\": [\n",
    "        #         \"Fireworks\",\n",
    "        #         \"Together\",\n",
    "        #     ],\n",
    "        # },\n",
    "    }\n",
    "\n",
    "    if is_anthropic_thinking_model(model_id):\n",
    "        thinking_budget_tokens = get_budget_tokens(model_id)\n",
    "        extra_body[\"reasoning\"] = {\n",
    "            \"max_tokens\": thinking_budget_tokens,\n",
    "        }\n",
    "        max_new_tokens = max_new_tokens + thinking_budget_tokens\n",
    "        # Remove the budget tokens suffix and add the thinking suffix\n",
    "        model_id = model_id.split(\"_\")[0] + \":thinking\"\n",
    "\n",
    "    if \"qwen\" in model_id:\n",
    "        # increase the max tokens by 4000\n",
    "        max_new_tokens = max_new_tokens + 4000\n",
    "else:\n",
    "    extra_body = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('gemini-images-unfaithfulness_analysis.yaml','r+', encoding='utf-8') as f:\n",
    "    data_images = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfaithful_metric_images_distribution = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "    4: 0,\n",
    "    5: 0,\n",
    "    6: 0,\n",
    "    7: 0,\n",
    "    8: 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem_name, problem_data in data_images['analysis_results'].items():\n",
    "    # print(problem_data['steps'])\n",
    "    # print(len(problem_data['steps'].items()))\n",
    "    total_steps = len(problem_data['steps'].items())\n",
    "    unfaithful_count_distribution = {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "        4: 0,\n",
    "        5: 0,\n",
    "        6: 0,\n",
    "        7: 0,\n",
    "        8: 0\n",
    "    }\n",
    "    for step_id, step_data in problem_data['steps'].items():\n",
    "        # print(step_data['unfaithfulness_analysis']['unfaithful_metric'])\n",
    "        unfaithful_metric = step_data['unfaithfulness_analysis']['unfaithful_metric']\n",
    "        unfaithful_count_distribution[unfaithful_metric] += 1\n",
    "    for unfaithful_metric_number, unfaithful_metric_count in unfaithful_count_distribution.items():\n",
    "        unfaithful_metric_images_distribution[unfaithful_metric_number] += unfaithful_metric_count/total_steps\n",
    "    # print(unfaithful_metric_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gemini-text-unfaithfulness_analysis.yaml','r+', encoding='utf-8') as f:\n",
    "    data_texts = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfaithful_metric_texts_distribution = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "    4: 0,\n",
    "    5: 0,\n",
    "    6: 0,\n",
    "    7: 0,\n",
    "    8: 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem_name, problem_data in data_texts['analysis_results'].items():\n",
    "    # print(problem_data['steps'])\n",
    "    # print(len(problem_data['steps'].items()))\n",
    "    total_steps = len(problem_data['steps'].items())\n",
    "    unfaithful_count_distribution = {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "        4: 0,\n",
    "        5: 0,\n",
    "        6: 0,\n",
    "        7: 0,\n",
    "        8: 0\n",
    "    }\n",
    "    for step_id, step_data in problem_data['steps'].items():\n",
    "        # print(step_data['unfaithfulness_analysis']['unfaithful_metric'])\n",
    "        unfaithful_metric = step_data['unfaithfulness_analysis']['unfaithful_metric']\n",
    "        unfaithful_count_distribution[unfaithful_metric] += 1\n",
    "    for unfaithful_metric_number, unfaithful_metric_count in unfaithful_count_distribution.items():\n",
    "        unfaithful_metric_texts_distribution[unfaithful_metric_number] += unfaithful_metric_count/total_steps\n",
    "    # print(unfaithful_metric_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Extract x and y values for both distributions\n",
    "x_values = list(range(0, 9))  # [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "y_images = [unfaithful_metric_images_distribution[i] for i in x_values]\n",
    "y_texts = [unfaithful_metric_texts_distribution[i] for i in x_values]\n",
    "\n",
    "# Format text labels\n",
    "text_images = [f'{val:.2f}' if val > 0 else '0.00' for val in y_images]\n",
    "text_texts = [f'{val:.2f}' if val > 0 else '0.00' for val in y_texts]\n",
    "\n",
    "# Create the grouped bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Images bars\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Images',\n",
    "    x=x_values,\n",
    "    y=y_images,\n",
    "    text=text_images,\n",
    "    textposition='outside',\n",
    "    textfont=dict(size=10, color='rgb(50, 50, 50)'),\n",
    "    marker_color='rgb(55, 83, 109)',  # Professional blue\n",
    "    marker_line_color='rgb(8, 48, 107)',\n",
    "    marker_line_width=1.5,\n",
    "    opacity=0.8\n",
    "))\n",
    "\n",
    "# Add Texts bars\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Texts',\n",
    "    x=x_values,\n",
    "    y=y_texts,\n",
    "    text=text_texts,\n",
    "    textposition='outside',\n",
    "    textfont=dict(size=10, color='rgb(50, 50, 50)'),\n",
    "    marker_color='rgb(158, 85, 156)',  # Complementary purple color\n",
    "    marker_line_color='rgb(120, 50, 118)',\n",
    "    marker_line_width=1.5,\n",
    "    opacity=0.8\n",
    "))\n",
    "\n",
    "# Update layout for grouped bars\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Weighted count of problems vs Faithful Metric(Gemini 2.0 Flash Experimental Thinking)',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 16, 'color': 'rgb(50, 50, 50)'}\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title='Faithful Metric',\n",
    "        tickmode='linear',\n",
    "        tick0=0,\n",
    "        dtick=1,\n",
    "        range=[-0.5, 8.5],\n",
    "        title_font={'size': 14},\n",
    "        tickfont={'size': 12}\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Weighed Count',\n",
    "        title_font={'size': 14},\n",
    "        tickfont={'size': 12}\n",
    "    ),\n",
    "    barmode='group',  # This creates the side-by-side grouped bars\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white',\n",
    "    width=900,\n",
    "    height=550,\n",
    "    margin=dict(l=80, r=40, t=100, b=80),\n",
    "    font=dict(\n",
    "        family=\"Arial, sans-serif\",\n",
    "        size=12,\n",
    "        color=\"rgb(50, 50, 50)\"\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update axes styling\n",
    "fig.update_xaxes(\n",
    "    showgrid=True, \n",
    "    gridwidth=1, \n",
    "    gridcolor='rgb(235, 235, 235)',\n",
    "    showline=True,\n",
    "    linewidth=1,\n",
    "    linecolor='rgb(204, 204, 204)'\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    showgrid=True, \n",
    "    gridwidth=1, \n",
    "    gridcolor='rgb(235, 235, 235)',\n",
    "    showline=True,\n",
    "    linewidth=1,\n",
    "    linecolor='rgb(204, 204, 204)'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
